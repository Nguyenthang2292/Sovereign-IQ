"""
Attention feature mixin for LSTM trainers.

This mixin is reserved for future attention-specific functionality.
Currently, attention behavior is handled through model creation flags.
"""


class AttentionFeatureMixin:
    """
    Mixin class for attention-specific functionality in LSTM trainers.

    This is a placeholder mixin for future attention-specific features.
    Currently, attention behavior is handled through model creation flags
    in the unified trainer. This mixin can be extended when attention-specific
    logic is needed.
    """

    pass
