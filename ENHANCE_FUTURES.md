# Enhancement Roadmap - Crypto Probability Trading System

T√†i li·ªáu n√†y m√¥ t·∫£ c√°c ƒë·ªÅ xu·∫•t n√¢ng c·∫•p v√† c·∫£i ti·∫øn cho h·ªá th·ªëng Crypto Probability Trading System, bao g·ªìm c√°c h∆∞·ªõng ph√°t tri·ªÉn ng·∫Øn h·∫°n, trung h·∫°n v√† d√†i h·∫°n.

## üìã M·ª•c l·ª•c

- [1. N√¢ng C·∫•p Thu·∫≠t To√°n & Chi·∫øn L∆∞·ª£c](#1-n√¢ng-c·∫•p-thu·∫≠t-to√°n--chi·∫øn-l∆∞·ª£c)
- [2. C·∫£i Ti·∫øn Machine Learning](#2-c·∫£i-ti·∫øn-machine-learning)
  - [2.7 N√¢ng C·∫•p XGBoost Module](#27-n√¢ng-c·∫•p-xgboost-module)
  - [2.8 N√¢ng C·∫•p Random Forest Module](#28-n√¢ng-c·∫•p-random-forest-module)
- [3. N√¢ng C·∫•p HMM Module](#3-n√¢ng-c·∫•p-hmm-module)
- [4. N√¢ng C·∫•p H·ªá Th·ªëng & Ki·∫øn Tr√∫c](#4-n√¢ng-c·∫•p-h·ªá-th·ªëng--ki·∫øn-tr√∫c)
- [5. T√≠ch H·ª£p D·ªØ Li·ªáu N√¢ng Cao](#5-t√≠ch-h·ª£p-d·ªØ-li·ªáu-n√¢ng-cao)
- [6. L·ªô Tr√¨nh Tri·ªÉn Khai](#6-l·ªô-tr√¨nh-tri·ªÉn-khai)

---

## 1. N√¢ng C·∫•p Thu·∫≠t To√°n & Chi·∫øn L∆∞·ª£c

### 1.1 Funding Rate Arbitrage (Delta Neutral)

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ ƒê√£ c√≥ `HedgeFinder` trong `modules/portfolio/hedge_finder.py`
- ‚úÖ H·ªó tr·ª£ multi-exchange qua `ExchangeManager`
- ‚ö†Ô∏è Ch∆∞a c√≥ module chuy√™n d·ª•ng cho funding rate arbitrage

**ƒê·ªÅ xu·∫•t:**
- **Chi·∫øn l∆∞·ª£c:** Long spot (ho·∫∑c futures s√†n A) v√† short futures Binance ƒë·ªÉ tri·ªát ti√™u delta, ƒÉn funding khi th·ªã tr∆∞·ªùng uptrend
- **Module m·ªõi:** `modules/funding_arbitrage/`
  - `funding_scanner.py`: Qu√©t funding rates gi·ªØa c√°c s√†n
  - `arbitrage_calculator.py`: T√≠nh to√°n l·ª£i nhu·∫≠n sau ph√≠ giao d·ªãch v√† tr∆∞·ª£t gi√°
  - `execution_manager.py`: Qu·∫£n l√Ω execution v·ªõi delta neutral constraints
- **T√≠ch h·ª£p:** S·ª≠ d·ª•ng `HedgeFinder` ƒë·ªÉ t√¨m hedge pairs, m·ªü r·ªông ƒë·ªÉ h·ªó tr·ª£ funding arbitrage

**Y√™u c·∫ßu k·ªπ thu·∫≠t:**
- Real-time funding rate monitoring
- T√≠nh to√°n ph√≠ giao d·ªãch ch√≠nh x√°c (maker/taker)
- M√¥ ph·ªèng tr∆∞·ª£t gi√° (slippage)
- Delta neutral position management

**Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
- `ccxt` (ƒë√£ c√≥) - Fetch funding rates
- `numpy` (ƒë√£ c√≥) - T√≠nh to√°n delta neutral

---

### 1.2 T·ªëi ∆Øu Danh M·ª•c Markowitz (Modern Portfolio Theory)

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ ƒê√£ c√≥ `PortfolioRiskCalculator` v·ªõi VaR, Beta calculation
- ‚úÖ ƒê√£ c√≥ `PortfolioCorrelationAnalyzer` cho correlation analysis
- ‚ö†Ô∏è Hedge hi·ªán t·∫°i d·∫°ng 1-1, ch∆∞a c√≥ portfolio optimization

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/portfolio/optimization.py`
  - `markowitz_optimizer.py`: Mean-Variance Optimization (MVO)
  - `efficient_frontier.py`: T√≠nh to√°n efficient frontier
  - `risk_parity.py`: Risk Parity portfolio allocation
- **T√≠ch h·ª£p:** M·ªü r·ªông `PortfolioRiskCalculator` ƒë·ªÉ h·ªó tr·ª£ portfolio optimization

**T√≠nh nƒÉng:**
- T·ªëi ∆∞u Sharpe ratio
- T·ªëi ∆∞u v·ªõi constraints (min/max weights, sector limits)
- Risk parity allocation
- Black-Litterman model (n·∫øu c√≥ views)

**Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
- `PyPortfolioOpt`: Portfolio optimization library
- `scipy.optimize` (ƒë√£ c√≥): Optimization algorithms

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.portfolio.optimization import MarkowitzOptimizer

optimizer = MarkowitzOptimizer(
    returns=returns_df,
    risk_free_rate=0.02
)
optimal_weights = optimizer.optimize_sharpe()
```

---

### 1.3 N√¢ng C·∫•p Pairs Trading

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ ƒê√£ c√≥ `modules/pairs_trading/` v·ªõi comprehensive quantitative metrics
- ‚úÖ H·ªó tr·ª£ Kalman Filter cho dynamic hedge ratio
- ‚úÖ Cointegration tests (ADF, Johansen)
- ‚ö†Ô∏è Ch∆∞a c√≥ backtesting engine cho pairs trading

**ƒê·ªÅ xu·∫•t c·∫£i ti·∫øn:**
- **Backtesting Engine:** `modules/pairs_trading/backtesting.py`
  - Walk-forward backtesting
  - In-sample/out-of-sample validation
  - Performance metrics (Sharpe, Calmar, Max Drawdown)
- **Advanced Strategies:**
  - Momentum pairs (ƒë√£ c√≥ preset nh∆∞ng c·∫ßn m·ªü r·ªông)
  - Pairs rotation strategy
  - Multi-pairs portfolio
- **Risk Management:**
  - Dynamic position sizing d·ª±a tr√™n volatility
  - Stop-loss v√† take-profit t·ª± ƒë·ªông
  - Correlation breakdown detection

---

### 1.4 Advanced Execution Algorithms

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚ö†Ô∏è H·∫ßu h·∫øt c√°c l·ªánh ƒë∆∞·ª£c g·ª≠i l√† Market ho·∫∑c Limit ƒë∆°n gi·∫£n.
- ‚ö†Ô∏è Ch∆∞a c√≥ ph√¢n chia l·ªánh l·ªõn (large orders) ƒë·ªÉ tr√°nh tr∆∞·ª£t gi√° (slippage).

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/execution/`
  - `twap.py`: Time-Weighted Average Price execution.
  - `vwap.py`: Volume-Weighted Average Price execution.
  - `iceberg.py`: ·∫®n kh·ªëi l∆∞·ª£ng th·ª±c t·∫ø c·ªßa l·ªánh.
  - `chase_limit.py`: T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh gi√° limit ƒë·ªÉ kh·ªõp l·ªánh m√† kh√¥ng d√πng market order.
- **L·ª£i √≠ch:**
  - Gi·∫£m impact cost v√† slippage cho c√°c l·ªánh l·ªõn.
  - T·ªëi ∆∞u h√≥a ƒëi·ªÉm v√†o l·ªánh (entry) v√† ra l·ªánh (exit).

---

### 1.5 Risk Management Core (Qu·∫£n tr·ªã r·ªßi ro chuy√™n s√¢u)

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚ö†Ô∏è Qu·∫£n tr·ªã r·ªßi ro ph√¢n t√°n trong t·ª´ng strategy.
- ‚ö†Ô∏è Ch∆∞a c√≥ h·ªá th·ªëng "Circuit Breaker" to√†n c·ª•c.

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/risk_management/`
  - `kelly_criterion.py`: T√≠nh to√°n size l·ªánh t·ªëi ∆∞u d·ª±a tr√™n win-rate v√† payoff ratio.
  - `vol_target.py`: ƒêi·ªÅu ch·ªânh size ƒë·ªÉ duy tr√¨ ƒë·ªô bi·∫øn ƒë·ªông danh m·ª•c m·ª•c ti√™u (v√≠ d·ª•: 15% annualized vol).
  - `circuit_breaker.py`: T·ª± ƒë·ªông ng·∫Øt trading n·∫øu drawdown trong ng√†y v∆∞·ª£t qu√° gi·ªõi h·∫°n (v√≠ d·ª•: -5%).
- **T√≠ch h·ª£p:**
  - Ho·∫°t ƒë·ªông nh∆∞ m·ªôt "gatekeeper" ch·∫∑n l·ªánh tr∆∞·ªõc khi g·ª≠i ra s√†n.

---

## 2. C·∫£i Ti·∫øn Machine Learning

### 2.1 Feature Engineering N√¢ng Cao

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ XGBoost module v·ªõi feature engineering c∆° b·∫£n
- ‚úÖ TFT (Temporal Fusion Transformer) ƒë√£ ƒë∆∞·ª£c implement
- ‚ö†Ô∏è Ch∆∞a c√≥ order book data, on-chain data, sentiment data

**ƒê·ªÅ xu·∫•t:**

#### 2.1.1 Order Book Imbalance
- **Module m·ªõi:** `modules/common/orderbook/`
  - `orderbook_fetcher.py`: Fetch order book data t·ª´ exchanges
  - `imbalance_calculator.py`: T√≠nh to√°n bid/ask imbalance
  - `orderflow_analyzer.py`: Ph√¢n t√≠ch order flow (delta, volume profile)
- **T√≠ch h·ª£p:** Th√™m order book features v√†o XGBoost v√† TFT pipelines
  - Xem chi ti·∫øt t√≠ch h·ª£p v·ªõi XGBoost t·∫°i [Section 2.7.5](#275-t√≠ch-h·ª£p-feature-engineering-n√¢ng-cao)
- **Timeframe:** Ng·∫Øn h·∫°n (<5 ph√∫t) cho scalping strategies

#### 2.1.2 On-Chain Data
- **Module m·ªõi:** `modules/common/onchain/`
  - `exchange_flow.py`: Exchange inflow/outflow
  - `whale_tracker.py`: Whale wallet monitoring
  - `network_metrics.py`: Network metrics (hash rate, active addresses)
- **T√≠ch h·ª£p:** V·ªõi timeframe l·ªõn (H4, D1) cho swing trading
- **Data sources:**
  - Glassnode API
  - CryptoQuant API
  - Blockchain.com API

#### 2.1.3 Sentiment Analysis
- **Module m·ªõi:** `modules/common/sentiment/`
  - `news_crawler.py`: Crawl news t·ª´ crypto news sites
  - `twitter_scraper.py`: Twitter sentiment analysis
  - `sentiment_analyzer.py`: VADER ho·∫∑c BERT-based sentiment scoring
- **T√≠ch h·ª£p:** Th√™m sentiment features v√†o ML models
  - Xem chi ti·∫øt t√≠ch h·ª£p v·ªõi XGBoost t·∫°i [Section 2.7.5](#275-t√≠ch-h·ª£p-feature-engineering-n√¢ng-cao)
- **Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
  - `vaderSentiment`: VADER sentiment analysis
  - `transformers`: BERT-based models
  - `tweepy`: Twitter API

---

### 2.2 Deep Learning cho Time-Series

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ ƒê√£ c√≥ TFT (Temporal Fusion Transformer) implementation
- ‚úÖ Data pipeline v√† feature selection ƒë√£ ƒë∆∞·ª£c implement
- ‚ö†Ô∏è C√≥ th·ªÉ m·ªü r·ªông v·ªõi c√°c ki·∫øn tr√∫c kh√°c

**ƒê·ªÅ xu·∫•t b·ªï sung:**

#### 2.2.1 LSTM/GRU Models
- **Module:** `modules/deeplearning/models/lstm.py`
- **Use case:** Gi·ªØ b·ªô nh·ªõ d√†i h·∫°n cho chu·ªói gi√°
- **T√≠ch h·ª£p:** Th√™m v√†o model registry, so s√°nh performance v·ªõi TFT

#### 2.2.2 Transformer Variants
- **N-BEATS:** Neural Basis Expansion Analysis
- **Informer:** Long sequence time-series forecasting
- **Autoformer:** Decomposition architecture

**Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
- `PyTorch Forecasting` (ƒë√£ c√≥ trong roadmap)
- `Darts`: Time series forecasting library

---

### 2.7 N√¢ng C·∫•p XGBoost Module

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ XGBoost module v·ªõi feature engineering c∆° b·∫£n
- ‚úÖ H·ªó tr·ª£ time-series cross-validation
- ‚ö†Ô∏è S·ª≠ d·ª•ng hyperparameters c·ªë ƒë·ªãnh
- ‚ö†Ô∏è Retrain model m·ªói khi ch·∫°y script
- ‚ö†Ô∏è Ch∆∞a c√≥ model persistence v√† version control
- ‚ö†Ô∏è Ch∆∞a c√≥ interpretability tools

**T·ªïng quan:**
Section n√†y t·∫≠p trung v√†o c√°c ƒë·ªÅ xu·∫•t n√¢ng c·∫•p cho XGBoost module, bao g·ªìm hyperparameter optimization, model persistence, interpretability, v√† t√≠ch h·ª£p v·ªõi meta-labeling.

---

#### 2.7.1 Hyperparameter Optimization (AutoML)

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ ƒê√£ implement hyperparameter optimization v·ªõi Optuna trong `modules/xgboost/optimization.py`
- ‚úÖ `HyperparameterTuner`: T·ª± ƒë·ªông t√¨m ki·∫øm b·ªô tham s·ªë t·ªëi ∆∞u v·ªõi Optuna
- ‚úÖ `StudyManager`: Qu·∫£n l√Ω v√† l∆∞u tr·ªØ k·∫øt qu·∫£ optimization studies
- ‚úÖ H·ªó tr·ª£ TimeSeriesSplit cross-validation
- ‚úÖ Study persistence v·ªõi SQLite database

**Implementation:**
Module ƒë√£ ƒë∆∞·ª£c implement t·∫°i `modules/xgboost/optimization.py` v·ªõi ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng nh∆∞ ƒë·ªÅ xu·∫•t ban ƒë·∫ßu. Module bao g·ªìm:
- `HyperparameterTuner`: Class ch√≠nh ƒë·ªÉ ch·∫°y optimization v·ªõi Optuna
- `StudyManager`: Qu·∫£n l√Ω v√† l∆∞u tr·ªØ studies v·ªõi SQLite database
- H·ªó tr·ª£ caching best parameters ƒë·ªÉ tr√°nh re-optimization kh√¥ng c·∫ßn thi·∫øt
- Integration v·ªõi existing XGBoost training pipeline

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.xgboost.optimization import HyperparameterTuner

tuner = HyperparameterTuner(
    symbol="BTCUSDT",
    timeframe="1h"
)
best_params = tuner.optimize(n_trials=100)
```

**Th∆∞ vi·ªán:** `optuna` (ƒë√£ ƒë∆∞·ª£c th√™m v√†o requirements-ml.txt)

---

#### 2.7.2 Model Persistence & MLOps

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚ö†Ô∏è Retrain model m·ªói khi ch·∫°y script -> T·ªën t√†i nguy√™n v√† th·ªùi gian, kh√¥ng hi·ªáu qu·∫£ cho high-frequency ho·∫∑c testing li√™n t·ª•c.
- ‚ö†Ô∏è Kh√¥ng l∆∞u l·∫°i l·ªãch s·ª≠ model ƒë·ªÉ so s√°nh hi·ªáu su·∫•t theo th·ªùi gian.

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/xgboost/persistence.py`
  - `model_registry.py`: Ch·ª©c nƒÉng L∆∞u/Load model (s·ª≠ d·ª•ng joblib ho·∫∑c pickle).
  - `version_control.py`: Qu·∫£n l√Ω metadata c·ªßa model (accuracy, timestamp, params, training data range).
- **Workflow:**
  - Khi kh·ªüi ƒë·ªông, ki·ªÉm tra xem c√≥ model ƒë√£ train (c√≤n h·∫°n, v√≠ d·ª• < 1h) cho symbol hi·ªán t·∫°i kh√¥ng.
  - N·∫øu c√≥ -> Load model v√† predict ngay l·∫≠p t·ª©c.
  - N·∫øu kh√¥ng ho·∫∑c model qu√° c≈© -> Retrain -> Save model m·ªõi v√†o registry.
- **Metadata l∆∞u tr·ªØ:**
  - Model version v√† timestamp
  - Training accuracy v√† validation metrics
  - Hyperparameters s·ª≠ d·ª•ng
  - Training data range (start_date, end_date)
  - Feature list v√† feature importance

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.xgboost.persistence import ModelRegistry

registry = ModelRegistry()
model = registry.load_or_train(
    symbol="BTCUSDT",
    max_age_hours=1
)
```

---

#### 2.7.3 Interpretability (Explainable AI - XAI)

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/xgboost/explanation.py`
  - `shap_analyzer.py`: T√≠nh to√°n SHAP (SHapley Additive exPlanations) values.
  - `feature_importance.py`: Visualization m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa t·ª´ng feature ƒë·ªëi v·ªõi quy·∫øt ƒë·ªãnh UP/DOWN.
- **L·ª£i √≠ch:**
  - "White-box" m√¥ h√¨nh: Hi·ªÉu t·∫°i sao model ƒë∆∞a ra d·ª± ƒëo√°n ƒë√≥.
  - V√≠ d·ª•: Model c√≥ th·ªÉ ch·ªâ ra r·∫±ng "RSI > 80" ƒëang ƒë√≥ng g√≥p 60% v√†o quy·∫øt ƒë·ªãnh "DOWN".
  - Gi√∫p trader t·ª± tin h∆°n khi v√†o l·ªánh ho·∫∑c l·ªçc b·ªè c√°c t√≠n hi·ªáu v√¥ l√Ω.
- **T√≠nh nƒÉng:**
  - Global feature importance (t·ªïng quan)
  - Local feature importance (cho t·ª´ng prediction)
  - SHAP waterfall plots
  - Feature interaction analysis

**Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
- `shap`: SHAP values calculation
- `matplotlib` / `plotly`: Visualization

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.xgboost.explanation import SHAPAnalyzer

analyzer = SHAPAnalyzer(model, X_test)
shap_values = analyzer.calculate_shap()
analyzer.plot_waterfall(prediction_idx=0)
```

---

#### 2.7.4 Meta-Labeling v·ªõi XGBoost

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/metalabeling/`
  - `base_signal_generator.py`: Model 1 - Indicator-based signals
  - `meta_classifier.py`: Model 2 - XGBoost predicts success probability
  - `signal_filter.py`: Filter signals based on meta-classifier confidence
- **Workflow:**
  1. Model 1 (Indicators) t·∫°o t√≠n hi·ªáu n·ªÅn
  2. Model 2 (XGBoost) d·ª± ƒëo√°n x√°c su·∫•t t√≠n hi·ªáu Model 1 s·∫Ω th√†nh c√¥ng
  3. Ch·ªâ execute signals v·ªõi confidence > threshold
- **L·ª£i √≠ch:** Lo·∫°i b·ªè false positives, tƒÉng win-rate

**T√≠ch h·ª£p:**
- S·ª≠ d·ª•ng existing indicators t·ª´ `modules/common/IndicatorEngine.py`
- S·ª≠ d·ª•ng XGBoost t·ª´ `modules/xgboost/`
- C√≥ th·ªÉ t·∫≠n d·ª•ng Model Persistence (2.7.2) v√† Interpretability (2.7.3)

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.metalabeling import MetaLabelingPipeline

pipeline = MetaLabelingPipeline(
    base_strategy="atc",  # ho·∫∑c "spc", "hmm", etc.
    confidence_threshold=0.7
)
filtered_signals = pipeline.filter_signals(raw_signals)
```

---

#### 2.7.5 T√≠ch H·ª£p Feature Engineering N√¢ng Cao

**T√≠ch h·ª£p v·ªõi Section 2.1:**
- **Order Book Features:** Th√™m order book imbalance v√†o XGBoost pipeline
- **On-Chain Data:** T√≠ch h·ª£p exchange flow, whale tracking cho timeframe l·ªõn
- **Sentiment Analysis:** Th√™m sentiment scores v√†o feature set

**Module m·ªü r·ªông:** `modules/xgboost/feature_engineering.py`
- T√≠ch h·ª£p c√°c feature m·ªõi t·ª´ `modules/common/orderbook/`, `modules/common/onchain/`, `modules/common/sentiment/`
- Feature selection t·ª± ƒë·ªông d·ª±a tr√™n importance scores
- Feature interaction detection

---

#### 2.7.6 Roadmap T√≠ch H·ª£p

**Ng·∫Øn h·∫°n (1-3 th√°ng):**
- ‚úÖ Hyperparameter Optimization (2.7.1) - **ƒê√£ ho√†n th√†nh**
- Model Persistence c∆° b·∫£n (2.7.2)

**Trung h·∫°n (3-6 th√°ng):**
- Model Persistence ƒë·∫ßy ƒë·ªß v·ªõi version control (2.7.2)
- Meta-Labeling v·ªõi XGBoost (2.7.4)
- T√≠ch h·ª£p Order Book features (2.7.5)

**D√†i h·∫°n (6-12 th√°ng):**
- Interpretability v·ªõi SHAP (2.7.3)
- T√≠ch h·ª£p On-Chain v√† Sentiment features (2.7.5)
- Advanced feature engineering v√† interaction detection (2.7.5)

---

### 2.8 N√¢ng C·∫•p Random Forest Module

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ Random Forest module v·ªõi feature engineering c∆° b·∫£n
- ‚úÖ H·ªó tr·ª£ SMOTE cho class imbalance
- ‚úÖ Model persistence c∆° b·∫£n (save/load v·ªõi joblib)
- ‚úÖ Model evaluation v·ªõi multiple confidence thresholds
- ‚úÖ ƒê√£ t√≠ch h·ª£p v√†o hybrid_analyzer v√† voting_analyzer
- ‚ö†Ô∏è S·ª≠ d·ª•ng hyperparameters c·ªë ƒë·ªãnh (n_estimators=100, min_samples_leaf=5)
- ‚ö†Ô∏è Ch∆∞a c√≥ hyperparameter optimization
- ‚ö†Ô∏è Model persistence ch∆∞a c√≥ version control v√† metadata management
- ‚ö†Ô∏è Ch∆∞a c√≥ interpretability tools
- ‚ö†Ô∏è Ch∆∞a c√≥ advanced feature selection

**T·ªïng quan:**
Section n√†y t·∫≠p trung v√†o c√°c ƒë·ªÅ xu·∫•t n√¢ng c·∫•p cho Random Forest module, t∆∞∆°ng t·ª± nh∆∞ XGBoost nh∆∞ng t·ªëi ∆∞u cho ƒë·∫∑c th√π c·ªßa Random Forest (ensemble methods, feature importance s·∫µn c√≥).

---

#### 2.8.1 Hyperparameter Optimization (AutoML)

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ ƒê√£ implement hyperparameter optimization v·ªõi Optuna trong `modules/random_forest/optimization.py`
- ‚úÖ `HyperparameterTuner`: T·ª± ƒë·ªông t√¨m ki·∫øm b·ªô tham s·ªë t·ªëi ∆∞u v·ªõi Optuna
- ‚úÖ `StudyManager`: Qu·∫£n l√Ω v√† l∆∞u tr·ªØ k·∫øt qu·∫£ optimization studies
- ‚úÖ H·ªó tr·ª£ TimeSeriesSplit cross-validation v·ªõi gap prevention
- ‚úÖ Study persistence v·ªõi SQLite database
- ‚úÖ T√≠ch h·ª£p v·ªõi SMOTE v√† class weights logic

**Implementation:**
Module ƒë√£ ƒë∆∞·ª£c implement t·∫°i `modules/random_forest/optimization.py` v·ªõi ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng nh∆∞ ƒë·ªÅ xu·∫•t ban ƒë·∫ßu. Module bao g·ªìm:
- `HyperparameterTuner`: Class ch√≠nh ƒë·ªÉ ch·∫°y optimization v·ªõi Optuna
- `StudyManager`: Qu·∫£n l√Ω v√† l∆∞u tr·ªØ studies v·ªõi SQLite database
- H·ªó tr·ª£ caching best parameters ƒë·ªÉ tr√°nh re-optimization kh√¥ng c·∫ßn thi·∫øt
- Integration v·ªõi existing Random Forest training pipeline (prepare_training_data, apply_smote, create_model_and_weights)

**Hyperparameters ƒë∆∞·ª£c optimize:**
- `n_estimators`: S·ªë l∆∞·ª£ng trees (50-500, step 50)
- `max_depth`: ƒê·ªô s√¢u t·ªëi ƒëa (5-30 ho·∫∑c None)
- `min_samples_split`: Minimum samples ƒë·ªÉ split (2-20)
- `min_samples_leaf`: Minimum samples trong leaf (1-10)
- `max_features`: S·ªë features ƒë·ªÉ xem x√©t khi split ('sqrt', 'log2', None)
- `class_weight`: Lu√¥n s·ª≠ d·ª•ng balanced weights (computed t·ª´ data)

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.random_forest.optimization import HyperparameterTuner

tuner = HyperparameterTuner(
    symbol="BTCUSDT",
    timeframe="1h"
)
best_params = tuner.optimize(df, n_trials=100)
```

**Th∆∞ vi·ªán:** `optuna` (ƒë√£ ƒë∆∞·ª£c th√™m v√†o requirements-ml.txt)

---

#### 2.8.2 Model Persistence & MLOps Enhancement

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ ƒê√£ c√≥ basic save/load v·ªõi joblib
- ‚ö†Ô∏è Ch∆∞a c√≥ version control v√† metadata management
- ‚ö†Ô∏è Ch∆∞a c√≥ model registry v√† automatic model refresh logic

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/random_forest/persistence.py`
  - `ModelRegistry`: Qu·∫£n l√Ω model registry v·ªõi version control
  - `ModelMetadata`: L∆∞u tr·ªØ metadata (accuracy, timestamp, params, training data range)
- **Workflow:**
  - Khi kh·ªüi ƒë·ªông, ki·ªÉm tra xem c√≥ model ƒë√£ train (c√≤n h·∫°n, v√≠ d·ª• < 1h) cho symbol hi·ªán t·∫°i kh√¥ng
  - N·∫øu c√≥ -> Load model v√† predict ngay l·∫≠p t·ª©c
  - N·∫øu kh√¥ng ho·∫∑c model qu√° c≈© -> Retrain -> Save model m·ªõi v√†o registry
- **Metadata l∆∞u tr·ªØ:**
  - Model version v√† timestamp
  - Training accuracy v√† validation metrics
  - Hyperparameters s·ª≠ d·ª•ng (bao g·ªìm optimized params t·ª´ 2.8.1)
  - Training data range (start_date, end_date)
  - Feature list v√† feature importance (s·∫µn c√≥ trong RF)
  - SMOTE configuration (ƒë√£ apply hay ch∆∞a)
  - Class distribution tr∆∞·ªõc v√† sau SMOTE

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.random_forest.persistence import ModelRegistry

registry = ModelRegistry()
model = registry.load_or_train(
    symbol="BTCUSDT",
    timeframe="1h",
    max_age_hours=1
)
```

---

#### 2.8.3 Interpretability (Explainable AI - XAI)

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/random_forest/explanation.py`
  - `FeatureImportanceAnalyzer`: Ph√¢n t√≠ch feature importance (s·∫µn c√≥ trong RF nh∆∞ng c·∫ßn visualization)
  - `SHAPAnalyzer`: T√≠nh to√°n SHAP values cho Random Forest
  - `TreeVisualizer`: Visualization individual trees
- **L·ª£i √≠ch:**
  - Random Forest ƒë√£ c√≥ feature importance s·∫µn, nh∆∞ng c·∫ßn tools ƒë·ªÉ visualize v√† explain t·ªët h∆°n
  - SHAP values cung c·∫•p local explanations cho t·ª´ng prediction
  - Tree visualization gi√∫p hi·ªÉu logic c·ªßa model
- **T√≠nh nƒÉng:**
  - Global feature importance (built-in nh∆∞ng c·∫ßn visualization)
  - Local feature importance v·ªõi SHAP (TreeExplainer)
  - SHAP waterfall plots
  - Feature interaction analysis (Random Forest t·ª± nhi√™n capture interactions)
  - Partial dependence plots

**Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
- `shap`: SHAP values calculation (TreeExplainer cho RF)
- `matplotlib` / `plotly`: Visualization
- `tree` (sklearn): Tree visualization

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.random_forest.explanation import SHAPAnalyzer, FeatureImportanceAnalyzer

# Feature importance
importance_analyzer = FeatureImportanceAnalyzer(model)
importance_analyzer.plot_importance()

# SHAP values
shap_analyzer = SHAPAnalyzer(model, X_test)
shap_values = shap_analyzer.calculate_shap()
shap_analyzer.plot_waterfall(prediction_idx=0)
```

---

#### 2.8.4 Meta-Labeling v·ªõi Random Forest

**ƒê·ªÅ xu·∫•t:**
- **T√≠ch h·ª£p v·ªõi Section 2.7.4 (Meta-Labeling module chung):**
  - Random Forest c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ meta-classifier thay v√¨ XGBoost
  - Random Forest c√≥ ∆∞u ƒëi·ªÉm: nhanh h∆°n, √≠t overfitting h∆°n, feature importance s·∫µn c√≥
- **Use cases:**
  - Khi c·∫ßn model nhanh h∆°n XGBoost cho real-time trading
  - Khi mu·ªën ensemble c·∫£ XGBoost v√† Random Forest cho meta-labeling
  - Khi mu·ªën interpretability t·ªët h∆°n (RF c√≥ feature importance t·ªët h∆°n)
- **T√≠ch h·ª£p:**
  - S·ª≠ d·ª•ng existing Random Forest training pipeline
  - C√≥ th·ªÉ k·∫øt h·ª£p v·ªõi XGBoost trong voting ensemble cho meta-labeling

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.metalabeling import MetaLabelingPipeline

pipeline = MetaLabelingPipeline(
    base_strategy="atc",
    meta_classifier="random_forest",  # ho·∫∑c "xgboost" ho·∫∑c "ensemble"
    confidence_threshold=0.7
)
filtered_signals = pipeline.filter_signals(raw_signals)
```

---

#### 2.8.5 Feature Selection & Engineering N√¢ng Cao

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/random_forest/feature_selection.py`
  - `RecursiveFeatureElimination`: RFE v·ªõi Random Forest
  - `FeatureImportanceSelector`: Feature selection d·ª±a tr√™n importance threshold
  - `PermutationImportance`: T√≠nh permutation importance ƒë·ªÉ validate feature importance
- **L·ª£i √≠ch:**
  - Random Forest c√≥ th·ªÉ handle nhi·ªÅu features nh∆∞ng feature selection gi√∫p:
    - Gi·∫£m overfitting
    - TƒÉng t·ªëc ƒë·ªô training
    - C·∫£i thi·ªán interpretability
- **T√≠ch h·ª£p:**
  - S·ª≠ d·ª•ng feature importance t·ª´ trained model
  - T·ª± ƒë·ªông select top-k features ho·∫∑c features v·ªõi importance > threshold
  - Retrain model v·ªõi selected features

**T√≠ch h·ª£p v·ªõi Section 2.1:**
- **Order Book Features:** Th√™m order book imbalance v√†o Random Forest pipeline
- **On-Chain Data:** T√≠ch h·ª£p exchange flow, whale tracking cho timeframe l·ªõn
- **Sentiment Analysis:** Th√™m sentiment scores v√†o feature set
- Random Forest c√≥ th·ªÉ handle mix of numerical v√† categorical features t·ªët

**Module m·ªü r·ªông:** `modules/random_forest/feature_engineering.py`
- T√≠ch h·ª£p c√°c feature m·ªõi t·ª´ `modules/common/orderbook/`, `modules/common/onchain/`, `modules/common/sentiment/`
- Feature selection t·ª± ƒë·ªông d·ª±a tr√™n importance scores
- Feature interaction detection (RF t·ª± nhi√™n capture nh∆∞ng c√≥ th·ªÉ explicit)

---

#### 2.8.6 Advanced Random Forest Variants

**ƒê·ªÅ xu·∫•t:**
- **Extra Trees (Extremely Randomized Trees):**
  - Module: `modules/random_forest/variants/extra_trees.py`
  - T∆∞∆°ng t·ª± RF nh∆∞ng random h∆°n, c√≥ th·ªÉ t·ªët h∆°n cho m·ªôt s·ªë datasets
- **Isolation Forest cho Anomaly Detection:**
  - Module: `modules/random_forest/variants/isolation_forest.py`
  - Ph√°t hi·ªán anomalies trong price movements
  - C√≥ th·ªÉ d√πng ƒë·ªÉ filter out bad signals
- **Random Forest Regressor cho Confidence Prediction:**
  - Module: `modules/random_forest/variants/confidence_predictor.py`
  - Train RF regressor ƒë·ªÉ predict confidence score thay v√¨ ch·ªâ classification
  - Cung c·∫•p continuous confidence thay v√¨ discrete probabilities

---

#### 2.8.7 Roadmap T√≠ch H·ª£p

**Ng·∫Øn h·∫°n (1-3 th√°ng):**
- ‚úÖ Hyperparameter Optimization v·ªõi Optuna (2.8.1) - **ƒê√£ ho√†n th√†nh**
- Model Persistence Enhancement v·ªõi version control (2.8.2)

**Trung h·∫°n (3-6 th√°ng):**
- Feature Selection & Engineering (2.8.5)
- Interpretability v·ªõi SHAP (2.8.3)
- Meta-Labeling integration (2.8.4)

**D√†i h·∫°n (6-12 th√°ng):**
- Advanced Random Forest Variants (2.8.6)
- T√≠ch h·ª£p On-Chain v√† Sentiment features (2.8.5)
- Advanced feature engineering v√† interaction detection (2.8.5)

---

## 3. N√¢ng C·∫•p HMM Module

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ ƒê√£ c√≥ 3 HMM strategies: Swings, KAMA, True High-Order HMM
- ‚úÖ Strategy registry v√† signal combiner
- ‚úÖ Multiple voting mechanisms
- ‚ö†Ô∏è C√≥ th·ªÉ m·ªü r·ªông v·ªõi c√°c bi·∫øn th·ªÉ HMM n√¢ng cao

### 3.1 Multivariate HMM (HMM ƒêa Bi·∫øn)

**ƒê·ªÅ xu·∫•t:**
- **M·ªü r·ªông:** `modules/hmm/core/multivariate.py`
- **√ù t∆∞·ªüng:** Thay v√¨ ch·ªâ quan s√°t m·ªôt chu·ªói d·ªØ li·ªáu, m√¥ h√¨nh quan s√°t vector ƒëa chi·ªÅu
- **D·ªØ li·ªáu ƒë·ªÅ xu·∫•t:**
  - Price Returns + Volume
  - Order Flow (Delta)
  - On-chain metrics (Exchange Inflow/Outflow)
- **L·ª£i √≠ch:** Tr·∫°ng th√°i th·ªã tr∆∞·ªùng ƒë∆∞·ª£c x√°c ƒë·ªãnh ch√≠nh x√°c h∆°n
  - V√≠ d·ª•: Gi√° tƒÉng nh∆∞ng Vol gi·∫£m ‚Üí "Bull Trap" thay v√¨ "Uptrend"

**K·∫ø th·ª´a:** Module `kama.py` ƒë√£ b·∫Øt ƒë·∫ßu h∆∞·ªõng n√†y v·ªõi feature matrix

---

### 3.2 Autoregressive HMM (AR-HMM)

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/hmm/core/ar_hmm.py`
- **V·∫•n ƒë·ªÅ:** HMM ti√™u chu·∫©n gi·∫£ ƒë·ªãnh observations ƒë·ªôc l·∫≠p, kh√¥ng ph√π h·ª£p v·ªõi momentum
- **Gi·∫£i ph√°p:** AR-HMM - observation ti·∫øp theo ph·ª• thu·ªôc v√†o c·∫£ hidden state V√Ä observations tr∆∞·ªõc ƒë√≥
- **·ª®ng d·ª•ng:** Hi·ªáu qu·∫£ cho trending markets
- **K·∫ø th·ª´a:** C√≥ th·ªÉ build tr√™n c·∫•u tr√∫c `high_order.py`

---

### 3.3 Hierarchical HMM (HHMM)

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/hmm/core/hierarchical.py`
- **C·∫•u tr√∫c:**
  - **L·ªõp tr√™n:** Ch·∫ø ƒë·ªô th·ªã tr∆∞·ªùng d√†i h·∫°n (Bull/Bear/Sideways)
  - **L·ªõp d∆∞·ªõi:** Bi·∫øn ƒë·ªông ng·∫Øn h·∫°n (Pullback, Rally, Noise)
- **L·ª£i √≠ch:** L·ªçc nhi·ªÖu, tr√°nh over-trading
  - V√≠ d·ª•: N·∫øu l·ªõp tr√™n l√† Bull, l·ªõp d∆∞·ªõi ch·ªâ k√≠ch ho·∫°t LONG khi c√≥ Pullback

---

### 3.4 HMM-GARCH

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/hmm/core/hmm_garch.py`
- **√ù t∆∞·ªüng:** M·ªói hidden state g·∫Øn v·ªõi m·ªôt GARCH model ri√™ng ƒë·ªÉ d·ª± b√°o volatility
- **·ª®ng d·ª•ng:** Qu·∫£n l√Ω r·ªßi ro
  - Khi HMM chuy·ªÉn sang "High Volatility" ‚Üí t·ª± ƒë·ªông gi·∫£m position size ho·∫∑c n·ªõi r·ªông stop-loss
- **Th∆∞ vi·ªán:** `arch` (ARCH/GARCH models)

---

### 3.5 Factorial HMM

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/hmm/core/factorial.py`
- **√ù t∆∞·ªüng:** T√°ch bi·∫øn ƒë·ªông gi√° th√†nh nhi·ªÅu ngu·ªìn ƒë·ªôc l·∫≠p (Factors)
- **C∆° ch·∫ø:**
  - Chu·ªói Markov 1: Tr·∫°ng th√°i th·ªã tr∆∞·ªùng chung (Bitcoin/Total Market)
  - Chu·ªói Markov 2: Tr·∫°ng th√°i n·ªôi t·∫°i c·ªßa Altcoin
- **L·ª£i √≠ch:** Ph√¢n lo·∫°i t√≠n hi·ªáu
  - Coin tƒÉng do "n∆∞·ªõc l√™n thuy·ªÅn l√™n" (Beta) hay do n·ªôi t·∫°i m·∫°nh (Alpha)

---

### 3.6 Input-Output HMM (IO-HMM)

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/hmm/core/io_hmm.py`
- **√ù t∆∞·ªüng:** Transition matrix kh√¥ng c·ªë ƒë·ªãnh m√† thay ƒë·ªïi ƒë·ªông d·ª±a tr√™n bi·∫øn s·ªë vƒ© m√¥
- **Input variables:**
  - BTC Dominance
  - Fear & Greed Index
  - Macro indicators (n·∫øu c√≥)
- **Tri·ªÉn khai:** Transition probabilities ƒë∆∞·ª£c t√≠nh l·∫°i d·ª±a tr√™n inputs
  - V√≠ d·ª•: P(Sideways ‚Üí Dump) tƒÉng khi Fear & Greed Index < 20

---

## 4. N√¢ng C·∫•p H·ªá Th·ªëng & Ki·∫øn Tr√∫c

### 4.1 Backtesting Engine

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚ö†Ô∏è Ch∆∞a c√≥ backtesting engine chuy√™n d·ª•ng
- ‚úÖ C√≥ Historical Simulation VaR trong `PortfolioRiskCalculator`
- ‚úÖ C√≥ performance analysis trong `pairs_trading`

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/backtesting/`
  - `backtester.py`: Core backtesting engine
  - `strategy_interface.py`: Standardized strategy interface
  - `performance_analyzer.py`: Performance metrics calculation
  - `visualization.py`: Equity curve, drawdown charts
- **T√≠nh nƒÉng:**
  - Walk-forward backtesting
  - In-sample/out-of-sample validation
  - Transaction cost modeling (fees, slippage)
  - Funding cost calculation (cho futures)
  - Multi-strategy backtesting
- **T√≠ch h·ª£p:**
  - T·∫•t c·∫£ strategies hi·ªán c√≥ (ATC, Range Oscillator, SPC, HMM, XGBoost, Random Forest)
  - Pairs trading strategies
  - Portfolio optimization strategies

**Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
- `vectorbt`: Vectorized backtesting
- `backtrader`: Event-driven backtesting framework

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from modules.backtesting import Backtester
from modules.adaptive_trend import ATCStrategy

strategy = ATCStrategy()
backtester = Backtester(
    strategy=strategy,
    data=historical_data,
    initial_capital=10000,
    commission=0.001
)
results = backtester.run()
backtester.plot_equity_curve()
```

---

### 4.2 Event-Driven Architecture

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ Fetch ‚Üí Analyze ‚Üí Print workflow (polling-based)
- ‚úÖ Multi-exchange support v·ªõi fallback
- ‚ö†Ô∏è Ch∆∞a c√≥ real-time streaming

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/realtime/`
  - `websocket_manager.py`: WebSocket connection management
  - `event_bus.py`: Event bus cho pub/sub pattern
  - `stream_processor.py`: Real-time data processing
  - `signal_emitter.py`: Emit signals khi c√≥ events
- **Ki·∫øn tr√∫c:**
  ```
  WebSocket ‚Üí Event Bus ‚Üí Strategy Listeners ‚Üí Signal Emitter ‚Üí Execution Engine
  ```
- **T√≠nh nƒÉng:**
  - Real-time price updates
  - Order book streaming
  - Trade execution events
  - Strategy signal events
- **L·ª£i √≠ch:**
  - Ph·∫£n ·ª©ng mili-gi√¢y
  - Kh√¥ng b·ªã delay do sleep loop
  - Scalable v·ªõi nhi·ªÅu strategies

**Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
- `ccxt` (ƒë√£ c√≥) - WebSocket support
- `asyncio` (built-in) - Async event handling
- `websockets`: WebSocket client/server

---

### 4.3 Web Dashboard

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚úÖ CLI interfaces cho t·∫•t c·∫£ modules
- ‚úÖ Colorama cho colored output
- ‚ö†Ô∏è Ch∆∞a c√≥ web UI

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/dashboard/`
  - `app.py`: Streamlit main application
  - `pages/`: Multi-page dashboard
    - `overview.py`: T·ªïng quan portfolio
    - `strategies.py`: Strategy performance
    - `signals.py`: Real-time signals
    - `backtesting.py`: Backtesting results
    - `settings.py`: Configuration
- **T√≠nh nƒÉng:**
  - Real-time PnL charts
  - Position tracking
  - Signal monitoring
  - Strategy performance comparison
  - Emergency "Close All" button
  - Configuration management
- **T√≠ch h·ª£p:**
  - T·∫•t c·∫£ modules hi·ªán c√≥
  - Real-time data t·ª´ WebSocket (n·∫øu c√≥)
  - Backtesting results visualization

**Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
- `streamlit` (ƒë√£ c√≥ trong requirements-ocr.txt)
- `plotly`: Interactive charts
- `pandas` (ƒë√£ c√≥): Data manipulation

---

### 4.4 Database & Data Persistence

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/database/`
  - `models.py`: SQLAlchemy models
  - `repository.py`: Data access layer
  - `migrations/`: Database migrations
- **D·ªØ li·ªáu l∆∞u tr·ªØ:**
  - Historical OHLCV data
  - Strategy signals v√† results
  - Backtesting results
  - Portfolio positions
  - Performance metrics
- **Database options:**
  - SQLite (development)
  - PostgreSQL (production)
  - TimescaleDB (time-series optimization)

**Th∆∞ vi·ªán ƒë·ªÅ xu·∫•t:**
- `SQLAlchemy`: ORM
- `Alembic`: Database migrations
- `TimescaleDB`: Time-series database extension

---

### 4.5 System Ops & Monitoring

**Tr·∫°ng th√°i hi·ªán t·∫°i:**
- ‚ö†Ô∏è Log file Text ƒë∆°n gi·∫£n.
- ‚ö†Ô∏è Ch∆∞a c√≥ c·∫£nh b√°o h·ªá th·ªëng (system health alerts) qua Telegram/Discord (ch·ªâ c√≥ t√≠n hi·ªáu trade).

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/ops/`
  - `heartbeat.py`: G·ª≠i t√≠n hi·ªáu "I'm alive" ƒë·ªãnh k·ª≥.
  - `rate_limit_guard.py`: Qu·∫£n l√Ω t·∫≠p trung API rate limits ƒë·ªÉ tr√°nh b·ªã ban IP.
  - `alert_bot.py`: Bot chuy√™n d·ª•ng b√°o l·ªói (Exceptions, Disconnects) v√† tr·∫°ng th√°i t√†i nguy√™n (RAM/CPU).
- **L·ª£i √≠ch:**
  - TƒÉng ƒë·ªô tin c·∫≠y c·ªßa trading bot ch·∫°y 24/7.
  - Ph√°t hi·ªán s·ªõm s·ª± c·ªë h·∫° t·∫ßng.

---

## 5. T√≠ch H·ª£p D·ªØ Li·ªáu N√¢ng Cao

### 5.1 Multi-Timeframe Analysis

**ƒê·ªÅ xu·∫•t:**
- **Module m·ªõi:** `modules/common/multitimeframe/`
  - `analyzer.py`: Ph√¢n t√≠ch signals tr√™n nhi·ªÅu timeframes
  - `consensus.py`: T·∫°o consensus t·ª´ multiple timeframes
- **Use case:**
  - Higher timeframe x√°c ƒë·ªãnh trend
  - Lower timeframe x√°c ƒë·ªãnh entry point
  - Conflict resolution gi·ªØa timeframes

---

### 5.2 Cross-Asset Analysis

**ƒê·ªÅ xu·∫•t:**
- **M·ªü r·ªông:** `modules/common/crossasset/`
  - `correlation_matrix.py`: Correlation gi·ªØa c√°c assets
  - `spillover_analyzer.py`: Ph√¢n t√≠ch spillover effects
  - `market_regime.py`: X√°c ƒë·ªãnh market regime t·ª´ multiple assets
- **T√≠ch h·ª£p:**
  - BTC dominance analysis
  - Stock market correlation (n·∫øu c√≥ data)
  - Commodity correlation

---

### 5.3 Alternative Data Sources

**ƒê·ªÅ xu·∫•t:**
- **Social Media:**
  - Reddit sentiment
  - Telegram channel analysis
  - Discord activity
- **Options Data:**
  - Put/Call ratios
  - Options flow
  - Implied volatility
- **Derivatives:**
  - Futures basis
  - Perpetual funding rates
  - Options skew

---

## 6. L·ªô Tr√¨nh Tri·ªÉn Khai

### 6.1 Ng·∫Øn H·∫°n (1-3 th√°ng)

**Priority: High**

1. **Backtesting Engine** (`modules/backtesting/`)
   - Core backtesting framework
   - T√≠ch h·ª£p v·ªõi existing strategies
   - Basic performance metrics

2. **Funding Rate Arbitrage** (`modules/funding_arbitrage/`)
   - Funding rate scanner
   - Arbitrage calculator
   - Delta neutral execution

3. **Order Book Features** (`modules/common/orderbook/`)
   - Order book data fetching
   - Imbalance calculation
   - T√≠ch h·ª£p v√†o XGBoost pipeline

4. **Web Dashboard** (`modules/dashboard/`)
   - Basic Streamlit app
   - Portfolio overview
   - Signal monitoring

5. **Risk Management Core** (`modules/risk_management/`)
   - Circuit Breakers
   - Kelly Criterion

---

### 6.2 Trung H·∫°n (3-6 th√°ng)

**Priority: Medium**

1. **Markowitz Optimization** (`modules/portfolio/optimization.py`)
   - Mean-Variance Optimization
   - Efficient frontier
   - Risk parity

2. **N√¢ng C·∫•p XGBoost Module** (Section 2.7)
   - ‚úÖ Hyperparameter Optimization v·ªõi Optuna (2.7.1) - **ƒê√£ ho√†n th√†nh**
   - Model Persistence & MLOps (2.7.2)
   - Meta-Labeling v·ªõi XGBoost (2.7.4)

3. **N√¢ng C·∫•p Random Forest Module** (Section 2.8)
   - Hyperparameter Optimization v·ªõi Optuna (2.8.1)
   - Model Persistence Enhancement v·ªõi version control (2.8.2)

5. **Advanced HMM Variants**
   - Multivariate HMM
   - AR-HMM
   - HMM-GARCH

6. **Event-Driven Architecture** (`modules/realtime/`)
   - WebSocket manager
   - Event bus
   - Real-time processing

7. **On-Chain Data** (`modules/common/onchain/`)
   - Exchange flow
   - Whale tracking
   - Network metrics

8. **Advanced Execution** (`modules/execution/`)
   - TWAP/VWAP algo
   - Iceberg orders
   
9. **System Ops** (`modules/ops/`)
   - Heartbeat & Health check
   - Rate limit manager

---

### 6.3 D√†i H·∫°n (6-12 th√°ng)

**Priority: Low (Research & Development)**

1. **Hierarchical HMM** (`modules/hmm/core/hierarchical.py`)
2. **Factorial HMM** (`modules/hmm/core/factorial.py`)
3. **Input-Output HMM** (`modules/hmm/core/io_hmm.py`)
4. **Sentiment Analysis** (`modules/common/sentiment/`)
5. **Database & Persistence** (`modules/database/`)
6. **Random Forest Module Enhancements** (Section 2.8)
   - Feature Selection & Engineering (2.8.5)
   - Interpretability v·ªõi SHAP (2.8.3)
   - Meta-Labeling integration (2.8.4)
   - Advanced Random Forest Variants (2.8.6)

7. **XGBoost Interpretability** (Section 2.7.3)
   - SHAP integration cho XGBoost
   - Feature importance visualization

8. **Advanced Deep Learning Models**
   - N-BEATS
   - Informer
   - Autoformer

---

## 7. Ghi Ch√∫ K·ªπ Thu·∫≠t

### 7.1 Module Structure Standard

T·∫•t c·∫£ modules m·ªõi n√™n tu√¢n theo c·∫•u tr√∫c chu·∫©n:

```
modules/new_module/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ core/              # Core logic
‚îú‚îÄ‚îÄ config/            # Configuration (n·∫øu c·∫ßn)
‚îú‚îÄ‚îÄ cli/               # CLI interface (n·∫øu c·∫ßn)
‚îú‚îÄ‚îÄ utils/             # Utilities
‚îî‚îÄ‚îÄ tests/             # Tests (trong tests/new_module/)
```

### 7.2 Testing Requirements

- Unit tests cho t·∫•t c·∫£ core functions
- Integration tests cho workflows
- Performance tests cho real-time components
- Backtesting validation cho strategies

### 7.3 Documentation Requirements

- README.md cho m·ªói module
- Docstrings cho t·∫•t c·∫£ public functions
- Examples v√† usage guides
- Architecture diagrams (n·∫øu ph·ª©c t·∫°p)

---

## 8. T√†i Nguy√™n & Tham Kh·∫£o

### 8.1 Th∆∞ Vi·ªán ƒê·ªÅ Xu·∫•t

- **Portfolio Optimization:** `PyPortfolioOpt`
- **Backtesting:** `vectorbt`, `backtrader`
- **Time-Series:** `Darts`, `PyTorch Forecasting`
- **Sentiment:** `vaderSentiment`, `transformers`
- **Database:** `SQLAlchemy`, `TimescaleDB`
- **Web:** `streamlit`, `plotly`

### 8.2 Papers & Research

- **Meta-Labeling:** "Advances in Financial Machine Learning" - Marcos Lopez de Prado
- **HMM Variants:** "Hidden Markov Models for Time Series" - Walter Zucchini
- **Portfolio Optimization:** "Modern Portfolio Theory" - Harry Markowitz
- **Event-Driven Architecture:** "Designing Data-Intensive Applications" - Martin Kleppmann

---

**Last Updated:** 2025
**Version:** 2.0
**Maintainer:** Crypto Probability Team
