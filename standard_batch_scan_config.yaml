# Standard Batch Scan Configuration Template
# This file can be used as a starting point for your custom scans.
# Place this file in the project root to have it detected by the scanner.

# ============================================================================
# GENERAL SETTINGS
# ============================================================================

analysis_mode: multi-timeframe # 'single-timeframe' or 'multi-timeframe'
timeframe: 15m # Used for single-timeframe mode
timeframes: # Used for multi-timeframe mode
  - 15m
  - 1h
  - 4h

cooldown: 2.5 # Seconds between batches (prevents API rate limiting)
limit: 700 # Number of candles per symbol

# ============================================================================
# MARKET COVERAGE (Symbol Selection)
# ============================================================================

max_symbols:
  null # Fixed count limit (null = all symbols)
  # The maximum number of symbols to include in a scan.
  # If set to null, all available symbols will be scanned.
  # Use this to limit the scan scope for performance or focus.

# ============================================================================
# STAGE 0 SAMPLING CONFIGURATION
# ============================================================================

stage0_sample_percentage:
  30 # Sample % (100 = no sampling)
  # The percentage of the market to select in Stage 0 sampling.
  # 100 means sample all symbols (no sampling applied).
  # Reduce this to scan a subset of symbols.

stage0_sampling_strategy:
  stratified # Sampling strategy to use
  # Available strategies:
  # - 'random': Pure random sampling (uniform probability)
  # - 'volume_weighted': Higher volume symbols have higher probability
  # - 'stratified': Divide into volume tiers, sample evenly from each (RECOMMENDED)
  # - 'top_n_hybrid': Top N% by volume + random for rest
  # - 'systematic': Every n-th symbol from volume-sorted list
  # - 'liquidity_weighted': Combines volume/volatility/spread (advanced)

# Strategy-specific parameters (only used by certain strategies)
stage0_stratified_strata_count: 3 # Number of strata for stratified sampling (default: 3 for top/mid/low)
stage0_hybrid_top_percentage: 50.0 # For top_n_hybrid: % of sample from top volume (default: 50%)

# ============================================================================
# PRE-FILTER CONFIGURATION
# ============================================================================

enable_pre_filter: true
pre_filter_mode: voting # 'voting' or 'hybrid'
pre_filter_percentage: 30.0 # Top % to select after filtering
pre_filter_auto_skip_threshold: 10 # Auto-skip percentage filter if Stage 3 returns fewer symbols than this

# Fast Mode Configuration
# Fast Mode (fast_mode: true) - RECOMMENDED:
#   Uses 3-stage sequential filtering for optimal performance:
#   - Stage 1: ATC scan only → keeps 100% of symbols that pass
#   - Stage 2: ATC + Range Oscillator + SPC → voting → keeps 100% that pass
#   - Stage 3: ATC + XGBoost + HMM + RF (ML models) → voting → keeps 100% that pass
#   Benefits: Much faster because ML models (XGBoost, HMM, RF) are only calculated
#             for symbols that already passed Stage 1 and 2 filtering.
#   Use case: Large market scans, frequent updates, production environments.
#
# Full Mode (fast_mode: false) - SLOW:
#   Calculates ALL indicators (ATC, Range Osc, SPC, XGBoost, HMM, RF) for ALL symbols
#   from the start, regardless of early filtering results.
#   Benefits: More thorough analysis, all indicators available for every symbol.
#   Use case: Small symbol sets, detailed analysis, research/backtesting.
#
# Note: Even in Fast Mode, Stage 3 still calculates all ML models (ignores fast_mode flag
#       for Stage 3) but only for symbols that passed Stage 2, making it much faster.
fast_mode: true

# ============================================================================
# SPC (SIMPLIFIED PERCENTILE CLUSTERING) CONFIGURATION
# ============================================================================

spc_config:
  preset: aggressive # 'conservative', 'balanced', 'aggressive', or null

  # Advanced parameters (only used if preset is null)
  volatility_adjustment: false
  use_correlation_weights: false
  time_decay_factor: 1.0
  interpolation_mode: linear
  min_flip_duration: 3
  flip_confidence_threshold: 0.6

  # Multi-timeframe SPC alignment
  # Enable multi-timeframe analysis for SPC signals. When enabled, the system
  # will check signal alignment across multiple timeframes to increase confidence.
  # This helps filter out false signals that only appear on a single timeframe.
  enable_mtf: true

  # List of timeframes to check for signal alignment. Signals must align across
  # these timeframes (if mtf_require_alignment is true) or show consistency
  # across them. Common combinations: ['1h', '4h'] or ['15m', '1h', '4h']
  mtf_timeframes:
    - 15m
    - 1h
    - 4h

  # If true, signals must align across ALL specified timeframes to be considered valid.
  # If false, signals are weighted by alignment percentage (more aligned = higher confidence).
  # Recommended: true for conservative filtering, false for more signal opportunities.
  mtf_require_alignment: true

# ============================================================================
# RANDOM FOREST CONFIGURATION
# ============================================================================
# Note: Model status and retrained flag are managed automatically by the system
# and do not need to be configured manually.

rf_training:
  # Force retraining even if model is valid
  # If true, the scanner will force a retrain before starting the scan.
  force_retrain: true

  auto_train_if_invalid: true
  training_symbols_mode: "auto" # 'auto' or 'manual'
  training_symbols_count: 10 # For auto mode
  manual_symbols: [] # For manual mode
  training_timeframe: "15m"
  training_limit: 1500

# ============================================================================
# ATC (ADAPTIVE TREND COMPONENT) CONFIGURATION
# ============================================================================
# For detailed optimization guide, see: modules/adaptive_trend_LTS/docs/SPEED_OPTIMIZATION_GUIDE.md

# ATC Core Parameters (for signal calculation)
atc_core:
  # Moving Average lengths (default: 28 for all)
  ema_len: 28
  hull_len: 28
  wma_len: 28
  dema_len: 28
  lsma_len: 28
  kama_len: 28
  
  # Moving Average initial weights (default: 1.0 for all)
  ema_w: 1.0
  hma_w: 1.0
  wma_w: 1.0
  dema_w: 1.0
  lsma_w: 1.0
  kama_w: 1.0
  
  # ATC algorithm parameters
  robustness: "Medium"  # "Narrow", "Medium", or "Wide" - sensitivity level
  lambda_param: 0.02    # Growth rate (equity increase) - range: 0.01-0.05
  decay: 0.03           # Decay rate (equity decrease) - range: 0.01-0.10
  cutout: 0             # Number of bars to skip at beginning (for backtesting: set to 20-50 to skip warm-up period)
  
  # Signal thresholds
  long_threshold: 0.1   # Threshold for LONG signal classification
  short_threshold: -0.1 # Threshold for SHORT signal classification
  
  # Backtesting Configuration ⚠️ IMPORTANT FOR BACKTESTING
  strategy_mode: false  # Set TRUE for backtesting to avoid look-ahead bias (shifts signal by 1 bar)
                        # - false: Signal uses current bar (for live trading/scanning)
                        # - true: Signal uses previous bar (for backtesting - prevents look-ahead)
                        # RECOMMENDED: true for backtesting, false for live trading

# Switch between ATC versions:
# - true: use 'modules/adaptive_trend_LTS' (High Performance - Rust/CUDA/Dask)
# - false: use 'modules/adaptive_trend' (Standard/Legacy)
use_atc_performance: true

atc_performance:
  # Preset 3: Medium Batch Scanning (100-1000 symbols) - GPU Accelerated
  batch_processing: false       # CUDA handles batching (set false when using CUDA)
  use_cuda: true                # GPU acceleration (REQUIRES CUDA Toolkit 12.x)
  parallel_l1: false            # CUDA handles parallelism (set false when using CUDA)
  parallel_l2: false            # CUDA handles parallelism (set false when using CUDA)
  prefer_gpu: true              # Auto-select GPU if available
  use_cache: true               # Cache intermediate results
  fast_mode: true               # Additional optimizations
  precision: "float32"           # Use float32 for speed (vs float64 for accuracy)
                                # RECOMMENDED FOR BACKTESTING: "float64" for accuracy
                                # Use "float32" for scanning (faster, ~5% tolerance acceptable)

  # Dask (Out-of-Core) Configuration
  use_dask: false               # Auto-enabled by system if symbols > 1000
  npartitions: null             # Number of Dask partitions (null = auto-calculated)
  
  # Incremental Updates (for live trading - NOT for backtesting)
  use_incremental: false        # Set true for live trading (10-100x faster for single bar updates)
                                 # ⚠️ NOT RECOMMENDED FOR BACKTESTING: Use full recalculation for accuracy
  
  # Memory Optimizations (for backtesting large datasets)
  use_memory_mapped: false      # Set true for very large backtesting datasets (>10GB)
                                 # Enables 90% memory reduction by using memory-mapped files
                                 # RECOMMENDED FOR BACKTESTING: true when dataset exceeds RAM
  use_compression: false        # Set true to reduce cache storage (5-10x smaller cache files)
                                 # RECOMMENDED FOR BACKTESTING: true to save disk space
  compression_level: 5          # Compression level (1-9, default: 5)
                                 # Higher = better compression but slower (use 5-7 for balance)
  
  # Advanced Settings
  warm_cache: false             # Pre-warm cache for repeated patterns
  use_codegen_specialization: false  # Enable JIT for hot path configs

approximate_ma_scanner:
  enabled: true            # Enable/disable approximate MA calculations (true = 2-3x faster, false = exact MAs)
                           # ⚠️ FOR BACKTESTING: Set false for full precision (exact MAs required for accurate results)
                           # Use true for scanning/filtering (2-3x faster, ~95% accuracy acceptable)
  use_adaptive: true       # Enable adaptive tolerance based on volatility
  num_threads: null        # Number of threads for parallel processing (null = auto-calculate based on CPU cores)
  volatility_window: 20    # Window size for volatility calculation
  base_tolerance: 0.05     # Base tolerance (5%) for adaptive mode
  volatility_factor: 1.0   # Multiplier for volatility impact on tolerance
